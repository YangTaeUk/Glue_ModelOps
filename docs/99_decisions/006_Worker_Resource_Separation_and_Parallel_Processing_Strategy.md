# ADR-006: Worker 리소스 분리 및 병렬 처리 전략

> **Status**: Accepted
> **Date**: 2024-12-27
> **Author**: System Architect
> **Context**: ADR-003(Temporal 채택) 후속 결정 — Worker 구성 및 리소스 분리 구체화
> **Supersedes**: N/A

---

## TL;DR (한 줄 요약)

> AI 파이프라인은 **리소스 이질적(Heterogeneous)** 단계들로 구성된다. 모든 단계를 동일한 Worker에서 처리하면 **고비용 리소스(GPU)가 저비용 작업(CPU) 대기 중 유휴**된다. Task Queue 기반 리소스 분리로 각 단계가 적합한 Worker에서 실행되도록 한다.

---

## 1. 문제 정의: 왜 리소스 분리가 필요한가

### 1.1 AI 파이프라인의 리소스 이질성

ADR-002에서 정의한 파이프라인 구조를 다시 살펴보자:

```
┌─────────────────────────────────────────────────────────────────────────┐
│                   AI 파이프라인의 리소스 이질성                          │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                          │
│   [Pre-Process] ──────▶ [Inference] ──────▶ [Post-Process]              │
│        │                     │                    │                      │
│        ▼                     ▼                    ▼                      │
│   ┌─────────┐          ┌─────────┐          ┌─────────┐                 │
│   │   CPU   │          │ 가속기  │          │   CPU   │                 │
│   │ 집약적  │          │ 집약적  │          │ 집약적  │                 │
│   └─────────┘          └─────────┘          └─────────┘                 │
│                                                                          │
│   예시:                 예시:                예시:                       │
│   • 토큰화              • GPU 추론           • 포맷 변환                 │
│   • 이미지 리사이즈     • NPU 추론           • 필터링                    │
│   • 오디오 디코딩       • TPU 추론           • 인코딩                    │
│                                                                          │
│   핵심 관찰:                                                             │
│   ──────────                                                             │
│   • 파이프라인 단계마다 필요한 리소스가 다름                             │
│   • Inference는 특수 하드웨어(가속기)가 필요할 수 있음                   │
│   • Pre/Post는 범용 CPU로 충분                                           │
│                                                                          │
└─────────────────────────────────────────────────────────────────────────┘
```

> **Note (Model-Agnostic)**: "가속기"는 GPU, NPU, TPU, 전용 ASIC 등 모든 추론 가속 하드웨어를 포괄한다. 특정 하드웨어에 종속되지 않는다.

### 1.2 분리하지 않으면 발생하는 문제

모든 파이프라인 단계를 동일한 Worker에서 처리하면:

```
┌─────────────────────────────────────────────────────────────────────────┐
│                   리소스 분리 없는 경우의 문제                           │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                          │
│   [문제 1: 고비용 리소스 유휴]                                          │
│   ──────────────────────────                                             │
│                                                                          │
│   시나리오: 가속기 탑재 Worker가 전체 파이프라인 담당                    │
│                                                                          │
│   ┌───────────────────────────────────────────────────────────────┐     │
│   │  Worker (가속기 탑재)                                          │     │
│   │                                                                 │     │
│   │  [Pre-Process]     [Inference]     [Post-Process]              │     │
│   │  ────────────      ───────────     ─────────────               │     │
│   │  CPU 작업 중       가속기 사용      CPU 작업 중                │     │
│   │       ↑                                 ↑                      │     │
│   │       └── 가속기 유휴 ──────────────────┘                      │     │
│   │                                                                 │     │
│   └───────────────────────────────────────────────────────────────┘     │
│                                                                          │
│   결과:                                                                  │
│   • 가속기가 CPU 작업 대기 중 유휴                                       │
│   • 비싼 자원의 활용률 저하                                              │
│   • 처리량(Throughput) 감소                                              │
│                                                                          │
│   ─────────────────────────────────────────────────────────────────      │
│                                                                          │
│   [문제 2: 리소스 제약으로 인한 확장 한계]                               │
│   ──────────────────────────────────────                                 │
│                                                                          │
│   시나리오: 가속기 없는 노드에서 Worker 확장 불가                        │
│                                                                          │
│   ┌────────────────────┐    ┌────────────────────┐                      │
│   │  Node A (가속기 O)  │    │  Node B (가속기 X)  │                      │
│   │  ──────────────────│    │  ──────────────────│                      │
│   │  Worker 실행 가능   │    │  Worker 실행 불가   │  ← 확장 제한        │
│   └────────────────────┘    └────────────────────┘                      │
│                                                                          │
│   결과:                                                                  │
│   • 가속기 노드만 Worker 배치 가능                                       │
│   • CPU 작업을 위해 비싼 가속기 노드 사용                                │
│   • 비용 효율성 저하                                                     │
│                                                                          │
│   ─────────────────────────────────────────────────────────────────      │
│                                                                          │
│   [문제 3: 배치 최적화 기회 상실]                                        │
│   ────────────────────────────                                           │
│                                                                          │
│   시나리오: 각 Worker가 파이프라인 전체를 순차 처리                      │
│                                                                          │
│   Worker 1: [Pre]──▶[Inference]──▶[Post] ──▶ [Pre]──▶[Inference]──▶...  │
│   Worker 2: [Pre]──▶[Inference]──▶[Post] ──▶ ...                        │
│                                                                          │
│   결과:                                                                  │
│   • Inference 단계를 배치(Batch)로 묶을 기회 없음                        │
│   • 가속기의 배치 처리 성능 활용 불가                                    │
│                                                                          │
└─────────────────────────────────────────────────────────────────────────┘
```

### 1.3 비즈니스 임팩트

| 문제 | 비즈니스 영향 |
|------|--------------|
| **가속기 유휴** | 비용 대비 처리량 감소, ROI 저하 |
| **확장 제한** | 부하 증가 시 대응력 저하 |
| **배치 미활용** | 지연 시간(Latency) 증가, 사용자 경험 저하 |

---

## 2. 전략적 결정: Task Queue 기반 리소스 분리

### 2.1 핵심 원칙

> **"파이프라인 단계를 리소스 특성에 따라 분리하고, 각 단계가 적합한 Worker에서 실행되도록 Task Queue로 라우팅한다."**

```
┌─────────────────────────────────────────────────────────────────────────┐
│                   Task Queue 기반 리소스 분리                            │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                          │
│   [파이프라인 실행 흐름]                                                 │
│   ────────────────────                                                   │
│                                                                          │
│   ┌─────────────────────────────────────────────────────────────────┐   │
│   │  Workflow (오케스트레이션)                                       │   │
│   │                                                                   │   │
│   │  scheduleActivity     scheduleActivity     scheduleActivity      │   │
│   │  (queue: "cpu")       (queue: "accel")     (queue: "cpu")        │   │
│   │        │                    │                    │               │   │
│   └────────┼────────────────────┼────────────────────┼───────────────┘   │
│            │                    │                    │                   │
│            ▼                    ▼                    ▼                   │
│   ┌────────────────┐   ┌────────────────┐   ┌────────────────┐          │
│   │  Task Queue    │   │  Task Queue    │   │  Task Queue    │          │
│   │  (CPU)         │   │  (Accelerator) │   │  (CPU)         │          │
│   └────────┬───────┘   └────────┬───────┘   └────────┬───────┘          │
│            │                    │                    │                   │
│            ▼                    ▼                    ▼                   │
│   ┌────────────────┐   ┌────────────────┐   ┌────────────────┐          │
│   │  CPU Worker    │   │  Accel Worker  │   │  CPU Worker    │          │
│   │  [Pre-Process] │   │  [Inference]   │   │  [Post-Process]│          │
│   └────────────────┘   └────────────────┘   └────────────────┘          │
│                                                                          │
│   효과:                                                                  │
│   ──────                                                                 │
│   • Pre/Post는 CPU Worker에서 실행 → 가속기 노드 불필요                 │
│   • Inference만 가속기 Worker에서 실행 → 가속기 활용률 극대화           │
│   • 각 Worker 유형을 독립적으로 확장 가능                               │
│                                                                          │
└─────────────────────────────────────────────────────────────────────────┘
```

### 2.2 Task Queue 분리 기준

| 기준 | 적용 시점 | 이점 |
|------|----------|------|
| **리소스 유형** | 기본 분리 | CPU vs 가속기 Worker 분리 |
| **우선순위** | 필요 시 | 긴급 작업 우선 처리 |
| **모델 특성** | 필요 시 | 대용량 모델 격리, 캐시 친화성 |

> **기본 전략**: 리소스 유형 기반 분리를 기본으로 하고, 필요에 따라 우선순위/모델 기반 분리를 추가한다. 구체적인 Queue 구성은 설계 문서에서 결정한다.

### 2.3 Worker 유형 정의

```
┌─────────────────────────────────────────────────────────────────────────┐
│                   Worker 유형 및 책임                                    │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                          │
│   ┌─────────────────────────────────────────────────────────────────┐   │
│   │  CPU Worker                                                      │   │
│   │  ──────────                                                      │   │
│   │  담당: 전처리, 후처리, 데이터 변환                               │   │
│   │  배포: 범용 노드 (가속기 불필요)                                 │   │
│   │  확장: 수평 확장 용이                                            │   │
│   └─────────────────────────────────────────────────────────────────┘   │
│                                                                          │
│   ┌─────────────────────────────────────────────────────────────────┐   │
│   │  Accelerator Worker                                              │   │
│   │  ──────────────────                                              │   │
│   │  담당: 추론(Inference) Activity 실행                             │   │
│   │  배포: 가속기 탑재 노드                                          │   │
│   │  확장: 가속기 가용성에 따름                                      │   │
│   └─────────────────────────────────────────────────────────────────┘   │
│                                                                          │
│   설계 원칙:                                                             │
│   ──────────                                                             │
│   • Worker 유형은 "리소스 특성"으로 구분 (하드웨어 종류 아님)            │
│   • 가속기 종류(GPU, NPU, TPU)는 Worker 내부 구현 세부사항              │
│   • Connector(ADR-004)가 실제 추론 엔진과 통신                          │
│                                                                          │
└─────────────────────────────────────────────────────────────────────────┘
```

---

## 3. 병렬 처리 전략

### 3.1 Activity 수준 병렬화

파이프라인 내 독립적인 Activity는 병렬 실행이 가능하다:

```
┌─────────────────────────────────────────────────────────────────────────┐
│                   Activity 병렬화 원칙                                   │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                          │
│   [순차 실행 필수]                    [병렬 실행 가능]                   │
│   ────────────────                    ────────────────                   │
│                                                                          │
│   의존 관계가 있는 Activity:          독립적인 Activity:                 │
│   [Pre] ──▶ [Inference] ──▶ [Post]   [ModelA]                           │
│                                       [ModelB] ──┐                       │
│   • 이전 단계 출력이 다음 입력        [ModelC] ──┼──▶ [Merge]           │
│   • 순차 실행 강제                               │                       │
│                                                  • 입력 공유, 출력 독립  │
│                                                  • 병렬 실행 후 병합     │
│                                                                          │
│   ─────────────────────────────────────────────────────────────────      │
│                                                                          │
│   결정 원칙:                                                             │
│   ──────────                                                             │
│   • ADR-002의 "선형 파이프라인" 원칙 준수                               │
│   • 파이프라인 전체는 선형이지만, 단일 단계 내에서 병렬화 가능          │
│   • 병렬 실행 결정은 파이프라인 정의 시 명시                            │
│                                                                          │
└─────────────────────────────────────────────────────────────────────────┘
```

### 3.2 Worker 슬롯 관리

Temporal Worker의 동시성 제어 원칙:

| 슬롯 유형 | 용도 | 관리 원칙 |
|----------|------|----------|
| **Workflow Slot** | 동시 실행 Workflow 수 | 메모리 기반 제한 |
| **Activity Slot** | 동시 실행 Activity 수 | 리소스 기반 제한 |

```
┌─────────────────────────────────────────────────────────────────────────┐
│                   슬롯 관리 원칙                                         │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                          │
│   [CPU Worker]                                                           │
│   ────────────                                                           │
│   • Activity Slot: CPU 코어 수 기반                                      │
│   • 상대적으로 많은 동시 실행 가능                                       │
│                                                                          │
│   [Accelerator Worker]                                                   │
│   ────────────────────                                                   │
│   • Activity Slot: 가속기 메모리 / 모델 크기 기반                        │
│   • 상대적으로 적은 동시 실행 (OOM 방지)                                 │
│                                                                          │
│   구체적 수치는 설계 문서에서 결정:                                      │
│   • 모델별 메모리 사용량 프로파일링 결과                                 │
│   • 배포 환경의 하드웨어 스펙                                            │
│   • 부하 테스트 결과                                                     │
│                                                                          │
└─────────────────────────────────────────────────────────────────────────┘
```

---

## 4. 배포 환경별 전략

### 4.1 단일 노드 vs 다중 노드

```
┌─────────────────────────────────────────────────────────────────────────┐
│                   배포 환경별 Worker 구성                                │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                          │
│   [단일 노드 배포]                                                       │
│   ────────────────                                                       │
│   적용: 개발 환경, 소규모 배포                                           │
│                                                                          │
│   ┌───────────────────────────────────────────────────────────────┐     │
│   │  Single Node                                                   │     │
│   │  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐           │     │
│   │  │ CPU Worker  │  │Accel Worker │  │Temporal     │           │     │
│   │  │ (Pre/Post)  │  │ (Inference) │  │Server       │           │     │
│   │  └─────────────┘  └─────────────┘  └─────────────┘           │     │
│   └───────────────────────────────────────────────────────────────┘     │
│                                                                          │
│   특성:                                                                  │
│   • 프로세스 간 통신 (낮은 오버헤드)                                     │
│   • 단순한 구성, 빠른 시작                                               │
│   • 자원 경합 가능성 (리소스 격리 주의)                                  │
│                                                                          │
│   ─────────────────────────────────────────────────────────────────      │
│                                                                          │
│   [다중 노드 배포]                                                       │
│   ────────────────                                                       │
│   적용: 프로덕션, 대규모 배포                                            │
│                                                                          │
│   ┌────────────────┐  ┌────────────────┐  ┌────────────────┐            │
│   │  CPU Node 1-N  │  │ Accel Node 1-M │  │ Temporal       │            │
│   │  ────────────  │  │  ────────────  │  │ Cluster        │            │
│   │  CPU Worker x N│  │ Accel Worker xM│  │                │            │
│   └────────────────┘  └────────────────┘  └────────────────┘            │
│                                                                          │
│   특성:                                                                  │
│   • 노드 유형별 독립 확장                                                │
│   • 장애 격리 (노드 단위)                                                │
│   • 네트워크 오버헤드 존재                                               │
│                                                                          │
└─────────────────────────────────────────────────────────────────────────┘
```

### 4.2 확장 전략 원칙

| 상황 | 확장 방향 | 판단 기준 |
|------|----------|----------|
| **CPU 작업 적체** | CPU Worker 추가 | CPU Queue 대기 시간 증가 |
| **추론 작업 적체** | Accelerator Worker 추가 | Accelerator Queue 대기 시간 증가 |
| **혼합 병목** | 병목 지점 분석 후 결정 | 모니터링 데이터 기반 |

> **원칙**: 모니터링 기반 확장 결정. 구체적인 임계치와 확장 자동화는 설계/운영 문서에서 결정한다.

---

## 5. 장애 격리 및 복구

### 5.1 Worker 장애 대응 원칙

```
┌─────────────────────────────────────────────────────────────────────────┐
│                   Worker 장애 대응                                       │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                          │
│   [Temporal의 기본 제공]                                                 │
│   ─────────────────────                                                  │
│   • Heartbeat 기반 Worker 생존 감지                                      │
│   • Activity 타임아웃 시 자동 재스케줄                                   │
│   • 다른 Worker로 작업 자동 이전                                         │
│                                                                          │
│   [우리가 결정해야 할 것]                                                │
│   ─────────────────────                                                  │
│   • Heartbeat 주기 (작업 특성에 따름)                                    │
│   • 재시도 정책 (ADR-003에서 원칙 정의됨)                                │
│   • 가속기 OOM 대응 전략                                                 │
│                                                                          │
│   ─────────────────────────────────────────────────────────────────      │
│                                                                          │
│   [가속기 OOM 대응 원칙]                                                 │
│   ─────────────────────                                                  │
│                                                                          │
│   1. 감지: 추론 엔진에서 OOM 에러 반환                                   │
│   2. 분류: 재시도 가능 여부 판단                                         │
│      • 일시적 메모리 부족 → 재시도 (다른 Worker로 라우팅)               │
│      • 모델 자체가 메모리 초과 → 실패 처리 (재시도 무의미)              │
│   3. 대응: Retry Policy에 따라 처리                                      │
│                                                                          │
└─────────────────────────────────────────────────────────────────────────┘
```

### 5.2 캐시 친화성 (Sticky Execution) 고려

| 고려 사항 | 설명 | 결정 |
|----------|------|------|
| **모델 로딩 비용** | 대용량 모델은 로딩에 수 초~수 분 소요 | 모델별 Worker 고정 고려 |
| **캐시 효율** | 동일 Worker에서 반복 실행 시 캐시 히트율 증가 | Task Queue 분리로 자연스럽게 달성 |

> **결정**: 기본적으로 Task Queue 분리로 캐시 친화성을 확보한다. 명시적 Sticky Execution이 필요한 경우 설계 문서에서 결정한다.

---

## 6. 트레이드오프 및 제약

### 6.1 감수하는 단점

| 단점 | 영향 | 보완 전략 |
|------|------|----------|
| **복잡도 증가** | Worker 유형별 관리 필요 | 자동화, 모니터링 강화 |
| **단계 간 데이터 전달** | 네트워크 오버헤드 | ADR-005 Dual Path로 대응 |
| **배치 처리 복잡** | Inference 배치 묶음 로직 필요 | 설계 문서에서 구체화 |

### 6.2 재검토 트리거

다음 상황 발생 시 이 결정을 재검토한다:

- [ ] 대부분의 파이프라인이 Pre/Post 없이 Inference만으로 구성될 경우
- [ ] 단계 간 데이터 전달 오버헤드가 처리 시간의 상당 부분을 차지할 경우
- [ ] 새로운 Temporal 기능이 더 나은 리소스 분리 방법을 제공할 경우

---

## 7. 결론

### 7.1 최종 결정 요약

| 결정 항목 | 결정 내용 | 핵심 논거 |
|----------|----------|----------|
| **분리 전략** | Task Queue 기반 리소스 분리 | 고비용 리소스 활용률 극대화 |
| **Worker 유형** | CPU Worker / Accelerator Worker | 리소스 이질성 대응 |
| **병렬화** | Activity 수준에서 병렬화 가능 | 선형 파이프라인 원칙 유지 |

### 7.2 핵심 메시지

> **"AI 파이프라인의 각 단계는 서로 다른 리소스를 필요로 한다. 모든 단계를 동일한 Worker에서 처리하면 고비용 자원(가속기)이 저비용 작업(CPU) 대기 중 유휴된다. Task Queue 기반 분리로 각 단계가 적합한 리소스에서 실행되도록 하여 비용 효율성과 처리량을 극대화한다."**

---

## 관련 문서 (Related)

- [ADR-002: AI 백엔드 범위 및 아키텍처 스타일](./002_Defining_Scope_and_Architecture_Style_of_AI_Backend_Application.md) — 파이프라인 구조 정의
- [ADR-003: 추론 작업 실행 모델](./003_Inference_Task_Execution_Model_and_State_Management_Strategy.md) — Temporal 채택, Worker 개념
- [ADR-005: 실시간 스트리밍 채널 전략](./005_Realtime_Streaming_Channel_Strategy.md) — Dual Path, 단계 간 데이터 전달
- [ADR-007: 추론 서버 배포와 Worker 통신 경계](./007_Inference_Server_Deployment_and_Worker_Communication_Boundary.md) — 배포 책임 분리, Worker-Server 분리 배포
- 02_architecture/04_worker.md — Worker 상세 설계 (구현 시 작성)

---

## 변경 이력 (Changelog)

| 날짜 | 작성자 | 변경 내용 |
|------|--------|----------|
| 2024-12-27 | System Architect | 초안 작성 — 결정 필요 사항 목록화 |
| 2024-12-27 | System Architect | 전면 재작성 — 문제 정의 보강, Model-Agnostic 원칙 적용, Why/What 원칙 준수 |
