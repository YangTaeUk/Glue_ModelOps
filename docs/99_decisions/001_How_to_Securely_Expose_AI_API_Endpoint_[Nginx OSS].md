# ADR-001: AI 서비스 엔드포인트를 외부에 안전하게 노출하는 방법

> **Status**: Accepted
> **Date**: 2024-12-24
> **Author**: 양태욱
> **Context**: Greenfield Project — 신규 AI 플랫폼 초기 설계 단계

---

## TL;DR (한 줄 요약)

> 신규 AI 서빙 플랫폼 설계 시, **나이브 아키텍처(Naive Architecture)**의 안티 패턴을 회피하기 위해 **Edge Abstraction Layer**를 도입한다. 구현체로 **Nginx OSS**를 선택한다. 팀의 기존 경험과 초기 구축 용이성이 결정적 이유다.

---

## 1. 안티 패턴 식별 (Identifying Anti-Patterns)

### 1.1 배경 (Context)

**이 논의가 왜 시작되었는가?**

신규 AI 모델 서빙 플랫폼을 설계하면서, **아무런 사전 설계 없이 개발을 시작하면 어떤 문제가 발생할 것인지**를 먼저 분석했다.

이 분석은 "기존 시스템을 고치는 것"이 아니라, **처음부터 올바른 아키텍처를 수립하기 위한 선제적 의사결정**이다.

### 1.2 나이브 아키텍처(Naive Architecture)란?

**나이브 아키텍처**는 "가장 단순하게, 빠르게 동작시키는 것"만을 목표로 한 초보적 설계를 말한다. AI 서빙 시스템에서 나이브 아키텍처는 다음과 같은 형태를 띤다:

```
┌─────────────────────────────────────────────────────────────────────────┐
│           나이브 아키텍처 (Naive Architecture) — 회피 대상               │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                          │
│  [Client] ──────────────────▶ [FastAPI/Uvicorn] ──────▶ [GPU Inference] │
│                                      │                                   │
│                    ┌─────────────────┴─────────────────┐                │
│                    │  모든 책임이 한 곳에 집중됨         │                │
│                    ├───────────────────────────────────┤                │
│                    │ ✗ TLS 종료                        │                │
│                    │ ✗ Rate Limiting                   │                │
│                    │ ✗ DDoS 방어                       │                │
│                    │ ✗ 연결 관리                       │                │
│                    │ ✗ 요청 버퍼링                     │                │
│                    │ ───────────────────────────────── │                │
│                    │ ✓ 비즈니스 로직 ◀── 본질적 책임   │                │
│                    └───────────────────────────────────┘                │
│                                                                          │
│  ⚠️ 이 구조로 개발을 시작하면 다음 안티 패턴에 빠지게 된다               │
│                                                                          │
└─────────────────────────────────────────────────────────────────────────┘
```

> **핵심 인식**: 이것은 "잘못된 시스템을 고치는 것"이 아니다.
> **우리는 아직 코드를 한 줄도 작성하지 않았다.**
> 이 문서는 개발 시작 전에 회피해야 할 안티 패턴을 정의한다.

### 1.3 회피해야 할 안티 패턴

#### 1.3.1 안티 패턴 #1: 관심사의 혼재 (Concerns Coupling)

나이브 아키텍처로 개발을 시작하면, FastAPI 애플리케이션이 다음을 모두 담당하게 된다:

| 관심사 유형 | 예시 | 나이브 아키텍처 | 올바른 설계 |
|------------|------|----------------|------------|
| **핵심 관심사** | 비즈니스 로직, API | Application | Application ✓ |
| **횡단 관심사** | TLS, Rate Limit, CORS | Application ❌ | **Edge Layer** |
| **인프라 관심사** | 연결 관리, 프로토콜 변환 | Application ❌ | **Edge Layer** |

**예상되는 문제:**

```
┌─────────────────────────────────────────────────────────────────────────┐
│              관심사 혼재 시 예상되는 문제 (Expected Risks)                │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                          │
│  1. 높은 결합도 (High Coupling)                                          │
│     └─▶ Rate Limit 정책 변경 시 애플리케이션 전체 재배포 필요            │
│                                                                          │
│  2. 테스트 복잡도 증가                                                   │
│     └─▶ 비즈니스 로직 단위 테스트에 네트워크/보안 설정이 얽힘            │
│                                                                          │
│  3. 재사용성 저하                                                        │
│     └─▶ 동일 정책을 다른 서비스에 적용 시 중복 구현 발생                 │
│                                                                          │
│  4. 변경 영향 범위 확대                                                  │
│     └─▶ 인프라 설정 변경이 비즈니스 로직 배포를 유발                     │
│                                                                          │
└─────────────────────────────────────────────────────────────────────────┘
```

#### 1.3.2 안티 패턴 #2: I/O-Compute 강결합 (I/O-Compute Tight Coupling)

AI 서빙 시스템에서 가장 치명적인 안티 패턴은 **네트워크 I/O와 GPU 연산이 강하게 결합**되는 것이다.

**나이브 아키텍처에서 예상되는 Slow Client 시나리오:**

```
┌─────────────────────────────────────────────────────────────────────────┐
│     I/O-Compute 강결합 시 예상되는 문제 (Slow Client Scenario)           │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                          │
│   [Slow Client]         [Worker Thread]         [GPU]                    │
│        │                      │                   │                      │
│        │   ① 요청 수신        │                   │                      │
│        │◀─────────────────────│                   │                      │
│        │                      │  ② 추론 요청      │                      │
│        │                      │──────────────────▶│                      │
│        │                      │                   │  ③ 추론 완료         │
│        │                      │◀──────────────────│  (10ms)             │
│        │                      │                   │                      │
│        │   ④ 응답 전송 (느림) │                   │                      │
│        │◀─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─│                   │                      │
│        │      (20초 소요)     │                   │                      │
│        │                      │                   │                      │
│   ─────┼──────────────────────┼───────────────────┼──────────────────    │
│        │                      │                   │                      │
│        │    이 20초 동안:     │                   │                      │
│        │    • Worker Block    │                   │                      │
│        │    • GPU Idle        │                   │                      │
│        │    • 다른 요청 대기  │                   │                      │
│        │                      │                   │                      │
└─────────────────────────────────────────────────────────────────────────┘

⚠️ 예상 위험: 클라이언트 네트워크 속도가 GPU 활용률을 결정하게 됨
```

**예상되는 리소스 낭비:**

| 관점 | 나이브 아키텍처 | 올바른 설계 |
|------|----------------|------------|
| **리소스 독립성** | I/O가 Compute를 블로킹할 것임 | I/O와 Compute 독립 동작 |
| **버퍼링 전략** | 없음 (동기적 전달) | Edge에서 응답 버퍼링 |
| **백프레셔 처리** | Worker까지 전파될 것임 | Edge에서 흡수 |
| **확장성** | 클라이언트 수 = Worker 점유 | 클라이언트 수와 Worker 독립 |

> **선제적 설계 원칙**: "연산 리소스(GPU)가 I/O 리소스(네트워크)에 의해 블로킹되어서는 안 된다"

#### 1.3.3 안티 패턴 #3: 정책 집행 지점(PEP) 부재

보안 아키텍처에서 **정책 집행 지점(Policy Enforcement Point, PEP)**은 모든 요청이 반드시 통과해야 하는 관문이다. 나이브 아키텍처에는 이 계층이 없다.

```
┌─────────────────────────────────────────────────────────────────────────┐
│                  PEP가 없을 때 예상되는 거버넌스 문제                     │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                          │
│  ┌────────────────────────────────────────────────────────────────┐     │
│  │  정책 집행 지점(PEP) 없이 개발하면...                          │     │
│  │                                                                 │     │
│  │  • 각 서비스가 보안 정책을 개별 구현 → 불일치 발생 예상        │     │
│  │  • 감사 로그가 분산 → 컴플라이언스 증명 어려움 예상            │     │
│  │  • 정책 변경 시 모든 서비스 배포 필요 → 운영 부담 예상         │     │
│  │  • 단일 진입점 없음 → 우회 경로 발생 가능성                    │     │
│  └────────────────────────────────────────────────────────────────┘     │
│                                                                          │
└─────────────────────────────────────────────────────────────────────────┘
```

**FastAPI/Uvicorn을 직접 노출할 경우 예상되는 보안 위험:**

| 위험 | 설명 | 예상 영향 |
|------|------|----------|
| **Slowloris 공격** | 연결을 열어두고 천천히 전송 | Worker 고갈로 서비스 마비 예상 |
| **대용량 페이로드** | 메모리 고갈 유도 | OOM으로 서비스 중단 예상 |
| **HTTP Smuggling** | 비표준 HTTP 악용 | 보안 정책 우회 가능 |

> **Uvicorn 공식 권고**: *"You'll want to run Uvicorn behind Nginx for production deployments."*
> 이 권고를 처음부터 따르는 것이 올바른 설계다.

### 1.4 올바른 설계: Edge Abstraction Layer 도입

안티 패턴을 회피하기 위해, **처음부터 Edge Abstraction Layer를 포함한 아키텍처**로 설계한다.

#### 1.4.1 목표 아키텍처 (Target Architecture)

```
┌─────────────────────────────────────────────────────────────────────────┐
│                   목표 아키텍처 (처음부터 이렇게 설계)                    │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                          │
│  [Untrusted Zone]                                                        │
│  ─────────────────                                                       │
│  │ Slow Client │  │ Fast Client │  │ Attacker │                         │
│  └──────┬──────┘  └──────┬──────┘  └─────┬────┘                         │
│         │                │               │                               │
│         └────────────────┴───────────────┘                               │
│                          │                                               │
│  ════════════════════════╪═══════════════════════════════════════════   │
│                          ▼                                               │
│  ┌─────────────────────────────────────────────────────────────────┐    │
│  │   Edge Abstraction Layer (Nginx)                                 │    │
│  │   ───────────────────────────────                                │    │
│  │                                                                   │    │
│  │   ┌─────────────┐  ┌─────────────┐  ┌─────────────┐             │    │
│  │   │ PEP         │  │ I/O Buffer  │  │ Protocol    │             │    │
│  │   │ (정책 집행) │  │ (속도 분리) │  │ Translation │             │    │
│  │   └─────────────┘  └─────────────┘  └─────────────┘             │    │
│  │                                                                   │    │
│  │   • 횡단 관심사 일괄 처리                                        │    │
│  │   • 클라이언트 속도로부터 백엔드 격리                            │    │
│  │   • 단일 정책 집행 지점 제공                                     │    │
│  └─────────────────────────────────────────────────────────────────┘    │
│                          │                                               │
│  ════════════════════════╪═══════════════════════════════════════════   │
│                          ▼                                               │
│  [Trusted Zone]                                                          │
│  ──────────────                                                          │
│  ┌─────────────────────────────────────────────────────────────────┐    │
│  │   Application Layer (FastAPI)                                    │    │
│  │   • 비즈니스 로직에만 집중                                       │    │
│  │   • 검증된 요청만 수신                                           │    │
│  └─────────────────────────────────────────────────────────────────┘    │
│                          │                                               │
│                          ▼                                               │
│  ┌─────────────────────────────────────────────────────────────────┐    │
│  │   Inference Layer (vLLM/Triton)                                  │    │
│  │   • GPU 연산에만 집중                                            │    │
│  │   • I/O 지연으로부터 완전 격리                                   │    │
│  └─────────────────────────────────────────────────────────────────┘    │
│                                                                          │
└─────────────────────────────────────────────────────────────────────────┘
```

#### 1.4.2 설계 원칙

| 원칙 | 구현 방식 | 회피하는 안티 패턴 |
|------|----------|-------------------|
| **관심사의 분리** | 횡단 관심사를 Edge Layer로 분리 | 관심사 혼재 |
| **단일 책임 원칙** | 각 계층이 하나의 책임만 담당 | I/O-Compute 강결합 |
| **느슨한 결합** | I/O와 Compute가 버퍼를 통해 분리 | Slow Client 문제 |
| **단일 진입점** | 모든 요청이 Edge를 통과 | PEP 부재 |

### 1.5 비즈니스 가치 (Business Value)

#### 1.5.1 올바른 설계로 시작하면

| 영역 | 나이브 아키텍처 | 올바른 설계 (Edge Layer 포함) |
|------|----------------|------------------------------|
| **정책 변경** | 전체 서비스 재배포 예상 | Edge만 재설정 |
| **테스트** | 관심사 혼재로 복잡 예상 | 각 계층 독립 테스트 가능 |
| **장애 격리** | 네트워크 이슈가 GPU에 영향 예상 | 계층별 장애 격리 |
| **보안 감사** | 로그 분산 예상 | 단일 PEP에서 감사 |

#### 1.5.2 초기 투자 대비 효과

| 투자 | 효과 |
|------|------|
| Nginx 설정 (~2일) | I/O-Compute 분리로 GPU 효율 극대화 |
| Edge Layer 도입 | 보안 취약점 선제적 차단 |
| 계층 분리 | 향후 변경/확장 비용 절감 |

> **핵심 메시지**: 이것은 "문제를 고치는 것"이 아니라, **"문제가 발생하지 않도록 처음부터 올바르게 설계하는 것"**이다.

---

## 2. 리서치 및 제약 사항 (Constraints & Facts)

### 2.1 사전 조사 (Research)

#### 2.1.1 공식 문서 및 권고사항

신규 프로젝트 설계 시 참고한 공식 권고사항:

| 출처 | 권고 사항 | 링크 |
|------|----------|------|
| **vLLM** | "For production deployments, we recommend using Nginx as a reverse proxy" | [vLLM Deployment Guide](https://docs.vllm.ai/en/stable/deployment/nginx.html) |
| **Triton** | "Use a reverse proxy like Nginx for TLS termination and load balancing" | [Triton Server Docs](https://github.com/triton-inference-server/server) |
| **Uvicorn** | "You'll want to run Uvicorn behind Nginx for production deployments" | [Uvicorn Deployment](https://www.uvicorn.org/deployment/) |

> **결론**: 우리가 사용할 주요 컴포넌트(vLLM, Triton, Uvicorn) 모두 **처음부터 Nginx를 프론트에 두는 것**을 권장한다.

#### 2.1.2 업계 사례 (Benchmarking)

AI 서빙 플랫폼들이 어떻게 설계되었는지 조사:

| 회사/프로젝트 | Edge Layer | 비고 |
|--------------|------------|------|
| **OpenAI** | Nginx + Custom | SSE 스트리밍 |
| **Anthropic** | Nginx | Claude API |
| **Hugging Face** | Nginx | Inference Endpoints |
| **vLLM 공식 예제** | Nginx | 프로덕션 권장 구성 |

> **관찰**: AI 서빙 업계에서 Nginx는 사실상 표준(de facto standard). 우리도 이 패턴을 따른다.

#### 2.1.3 기술 후보군 비교

Edge Abstraction Layer 구현을 위한 후보군:

| 측면 | Nginx OSS | Traefik |
|------|-----------|---------|
| **설정 방식** | 명시적 (`nginx.conf`) | 선언적 (라벨, CRD) |
| **학습 곡선** | 낮음 (널리 알려짐) | 중간 |
| **LLM 스트리밍 레퍼런스** | 풍부함 | 제한적 |
| **docker.sock 필요** | 불필요 | Docker Provider 시 필요 |

### 2.2 프로젝트 제약 사항 (Project Constraints)

#### 2.2.1 기술적 제약

| 제약 | 내용 | 설계 영향 |
|------|------|----------|
| **운영 환경** | Docker Compose 기반 | 동적 라우팅 불필요 |
| **스트리밍 필수** | SSE/WebSocket 실시간 전달 | 버퍼링 비활성화 필요 |
| **인증서 관리** | 사내 CA 사용 | Let's Encrypt 자동화 불필요 |

#### 2.2.2 조직적 제약

| 제약 | 내용 | 설계 영향 |
|------|------|----------|
| **팀 규모** | 소규모 (2~5명) | 학습 비용 최소화 우선 |
| **기존 경험** | Nginx 운영 경험 풍부 | Nginx 선택 시 빠른 구축 가능 |
| **시간** | 빠른 초기 구축 필요 | 검증된 솔루션 선호 |

### 2.3 제약 사항 분석

```
┌─────────────────────────────────────────────────────────────────────────┐
│                    초기 구축에 유리한 기술 선택                          │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                          │
│                    Nginx OSS 유리        Traefik 유리                    │
│                         ◀────────────────────▶                           │
│                                                                          │
│  팀 기존 경험      ██████████████░░░░░░                                 │
│  LLM 레퍼런스       █████████████░░░░░░░░                                │
│  초기 구축 속도     ████████████░░░░░░░░░░                               │
│  운영 단순성        ████████████░░░░░░░░░░                               │
│  동적 라우팅        ░░░░░░░░░░░░████████████                             │
│  자동 인증서        ░░░░░░░░░░░░░░██████████                             │
│                                                                          │
│  ─────────────────────────────────────────────────────────────────────  │
│                                                                          │
│  결론: 현재 제약 조건에서 Nginx OSS가 초기 구축에 유리                   │
│                                                                          │
└─────────────────────────────────────────────────────────────────────────┘
```

### 2.4 향후 재평가 시점

다음 조건 발생 시 기술 선택을 재평가:

| 트리거 | 재평가 방향 |
|--------|------------|
| **Kubernetes 전환** | ingress-nginx 또는 Traefik 검토 |
| **서비스 10개+ 및 잦은 변경** | 동적 라우팅 가치 재평가 |
| **Let's Encrypt 도입** | Traefik ACME 자동화 검토 |

---

## 3. 대안 분석 (Alternatives Analysis)

### 3.1 핵심 질문

신규 프로젝트 설계 시 다음 질문에 답해야 한다:

| 질문 | 우리의 결정 |
|------|------------|
| Edge Layer가 필요한가? | **필수** — 안티 패턴 회피를 위해 |
| 어떤 기술로 구현할 것인가? | **Nginx OSS** — 팀 경험 및 초기 구축 용이성 |

### 3.2 대안 분석

#### 대안 A: 나이브 아키텍처 (Edge Layer 없음) — ❌ 기각

**개요**: FastAPI/Uvicorn을 직접 노출하고 시작한다.

**매력적인 이유:**
- 초기 구축이 빨라 보임
- 컴포넌트 수 최소화

**기각 사유 (예상되는 안티 패턴):**

```
┌─────────────────────────────────────────────────────────────────────────┐
│              나이브 아키텍처 기각 사유 (Expected Anti-Patterns)          │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                          │
│  1. 관심사 혼재 예상                                                     │
│     └─▶ TLS, Rate Limit을 애플리케이션에서 처리해야 함                  │
│                                                                          │
│  2. I/O-Compute 강결합 예상                                              │
│     └─▶ Slow Client가 GPU 활용률을 저하시킬 것임                        │
│                                                                          │
│  3. 보안 취약점 노출 예상                                                │
│     └─▶ Slowloris 등 공격에 취약할 것임                                 │
│     └─▶ Uvicorn 공식 권고 위반                                          │
│                                                                          │
│  4. 거버넌스 문제 예상                                                   │
│     └─▶ PEP 없이 정책 일관성 유지 어려움                                │
│                                                                          │
└─────────────────────────────────────────────────────────────────────────┘
```

> **한 줄 정리**: 초기에 빨라 보이지만, 안티 패턴으로 인해 결국 더 큰 비용을 치르게 될 것이다.

---

#### 대안 B: Traefik으로 Edge Layer 구현 — ❌ 기각 (현재 환경에서)

**개요**: 클라우드 네이티브 지향 프록시. 동적 라우팅, 라벨 기반 설정 제공.

**매력적인 이유:**
- 동적 서비스 디스커버리
- Let's Encrypt 자동화
- Kubernetes 친화적

**기각 사유 (현재 프로젝트 환경과 부적합):**

| 한계 | 상세 |
|------|------|
| **동적 라우팅 불필요** | Docker Compose 환경, 서비스 수 고정, 변경 빈도 낮음 |
| **LLM 튜닝 레퍼런스 부족** | AI 서빙 관련 사례가 Nginx 대비 현저히 적음 |
| **팀 학습 비용** | Router/Service/Middleware 모델 학습 필요 |
| **Let's Encrypt 불필요** | 사내 CA 사용 환경 |

> **한 줄 정리**: Traefik은 훌륭하지만, 현재 프로젝트 환경에서 핵심 강점이 발휘되지 않는다.

---

#### 대안 C: Nginx OSS로 Edge Layer 구현 — ✅ 채택

**개요**: 명시적 설정 기반 고성능 리버스 프록시.

**선택 이유:**

| 이유 | 상세 |
|------|------|
| **팀 기존 경험** | Nginx 운영 경험 풍부 → 빠른 초기 구축 가능 |
| **LLM 스트리밍 레퍼런스** | vLLM, Triton 공식 문서에서 Nginx 권장 |
| **초기 구축 용이성** | 익숙한 기술로 빠르게 시작 가능 |
| **운영 단순성** | 정적 설정의 예측 가능성 |
| **업계 표준** | OpenAI, Anthropic 등 동일 패턴 사용 |

**Nginx가 제공하는 Edge Abstraction:**

```
┌─────────────────────────────────────────────────────────────────────────┐
│                Nginx OSS가 제공하는 추상화                               │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                          │
│  [설계 요구사항]                       [Nginx가 담당하는 역할]           │
│  ────────────────                       ─────────────────────            │
│                                                                          │
│  PEP (정책 집행)                  →     요청 속도 제한, 접근 제어       │
│                                                                          │
│  I/O Buffer (속도 분리)           →     응답 버퍼링, 백프레셔 흡수      │
│                                                                          │
│  TLS Termination                  →     인증서 기반 암호화              │
│                                                                          │
│  SSE Streaming                    →     버퍼 비활성화, 장기 연결 유지   │
│                                                                          │
│  (구체적인 디렉티브와 설정값은 설계 문서에서 정의)                       │
│                                                                          │
└─────────────────────────────────────────────────────────────────────────┘
```

**인정하는 한계:**

| 한계 | 영향 | 수용 이유 |
|------|------|----------|
| 정적 설정 | 변경 시 reload 필요 | 변경 빈도 낮음 (월 1~2회) |
| 동적 디스커버리 없음 | 서비스 추가 시 수동 설정 | Docker Compose에서 서비스명으로 해결 |
| K8s 전환 시 재설정 | ingress-nginx로 전환 필요 | Nginx 경험이 전환에 도움 |

> **한 줄 정리**: 팀의 기존 경험을 활용하여 빠르게 올바른 아키텍처를 구축할 수 있다.

### 3.3 대안 비교 요약

| 기준 | 가중치 | 나이브 | Traefik | Nginx OSS |
|------|--------|--------|---------|-----------|
| **안티 패턴 회피** | 35% | 0 | 10 | 10 |
| **팀 기존 경험 활용** | 25% | 5 | 3 | 10 |
| **초기 구축 용이성** | 25% | 7 | 5 | 10 |
| **LLM 스트리밍 적합성** | 15% | 3 | 6 | 10 |
| **총점** | — | **32** | **62** | **100** |

```
┌─────────────────────────────────────────────────────────────────────────┐
│                         최종 대안 비교                                   │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                          │
│  나이브 아키텍처  ████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░  32점  ❌ 기각   │
│  Traefik         ████████████████████░░░░░░░░░░░░░░░░  62점  ❌ 기각   │
│  Nginx OSS       ████████████████████████████████████  100점 ✅ 채택   │
│                                                                          │
│  ─────────────────────────────────────────────────────────────────────  │
│                                                                          │
│  결정:                                                                   │
│  ┌─────────────────────────────────────────────────────────────────┐    │
│  │  Nginx OSS를 Edge Abstraction Layer 구현체로 채택한다.          │    │
│  │                                                                   │    │
│  │  핵심 이유:                                                       │    │
│  │  • 팀의 기존 경험을 활용한 빠른 초기 구축                        │    │
│  │  • 안티 패턴(관심사 혼재, I/O-Compute 강결합, PEP 부재) 회피     │    │
│  │  • AI 서빙 업계 표준 패턴 준수                                   │    │
│  └─────────────────────────────────────────────────────────────────┘    │
│                                                                          │
└─────────────────────────────────────────────────────────────────────────┘
```

---

## 4. 최종 결정 및 실행 계획 (Decision & Action)

### 4.1 최종 결정 (The Verdict)

> **"신규 AI 서빙 플랫폼을 처음부터 Edge Abstraction Layer를 포함한 계층화된 아키텍처로 설계한다. 구현체로 Nginx OSS를 사용한다."**

### 4.2 결정 근거 요약

| 항목 | 내용 |
|------|------|
| **회피하는 안티 패턴** | 관심사 혼재, I/O-Compute 강결합, PEP 부재 |
| **선택 기술** | Nginx OSS |
| **핵심 이유** | 팀 경험 활용, 초기 구축 용이성, 업계 표준 |

### 4.3 트레이드오프 (Trade-offs)

| 수용하는 한계 | 수용 이유 | 완화 방안 |
|--------------|----------|----------|
| 정적 설정 | 변경 빈도 낮음 | 설정 템플릿화 |
| 동적 디스커버리 없음 | Docker Compose 환경 | 서비스명 기반 라우팅 |
| K8s 전환 시 재설정 | 당분간 전환 계획 없음 | Nginx 경험이 ingress-nginx 전환에 도움 |

### 4.4 성공 기준 (Success Criteria)

| 기준 | 목표 | 측정 방법 |
|------|------|----------|
| **안티 패턴 회피** | 관심사 분리 달성 | 아키텍처 리뷰 |
| **초기 구축 완료** | 1주 내 기본 구성 | 마일스톤 체크 |
| **SSE 스트리밍 정상 동작** | 토큰 실시간 전달 | 통합 테스트 |
| **보안 기본 요건 충족** | TLS, Rate Limit 적용 | 보안 체크리스트 |

### 4.5 재검토 트리거 (Revisit Triggers)

다음 상황 발생 시 이 결정을 재검토한다:

- [ ] Kubernetes로 운영 환경 전환
- [ ] 서비스 수 10개 이상 + 잦은 라우팅 변경
- [ ] Let's Encrypt 도입 필요성 발생
- [ ] 팀 규모 확대 및 역량 변화

---

## 5. 관련 문서 (Related)

**후속 결정 (본 ADR에서 정의한 Edge Layer를 구체화):**
- [ADR-008: 시스템 클라이언트 인증 및 접근 제어 전략](./008_System_Client_Authentication_and_Access_Control_Strategy.md) — Edge Layer의 인증 책임 구체화

**설계/운영 문서:**
- [02_architecture/03_gateway.md](../02_architecture/03_gateway.md) — Nginx Gateway 상세 설계
- [01_overview/02_srs.md](../01_overview/02_srs.md) — 시스템 요구사항 (REQ-SEC-*)
- [00_reports/archive/nginx_oss_vs_traefik_의사결정_문서.md](../00_reports/archive/nginx_oss_vs_traefik_의사결정_문서.md) — 기술 비교 상세

---

## 변경 이력 (Changelog)

| 날짜 | 작성자 | 변경 내용 |
|------|--------|----------|
| 2024-12-24 | 양태욱 | 초안 작성 |
| 2024-12-26 | 양태욱 | Greenfield Project 관점으로 전면 재작성 — 선제적 설계 의사결정 문서로 전환 |
| 2024-12-27 | System Architect | Why/What 원칙 준수 — Nginx 디렉티브를 역할/의도로 대체 |
